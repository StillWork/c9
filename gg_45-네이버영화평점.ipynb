{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네이버영화평점\n",
    "==\n",
    "- 감성분석\n",
    "- 네이버 영화평점 데이터(https://github.com/e9t/nsmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 28 23:13:50 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 384.130                Driver Version: 384.130                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:03:00.0  On |                  N/A |\r\n",
      "| 24%   43C    P8    17W / 250W |     18MiB / 11170MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\r\n",
      "| 23%   35C    P8    17W / 250W |      2MiB / 11172MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      2002      G   /usr/lib/xorg/Xorg                            15MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로지스틱회귀를 이용한 감성분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import konlpy\n",
    "import pandas as pd\n",
    "from konlpy.tag import Twitter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pickle\n",
    "import os.path\n",
    "\n",
    "df_train = pd.read_csv('data/ratings_train.txt', delimiter='\\t', keep_default_na=False)\n",
    "df_test = pd.read_csv('data/ratings_test.txt', delimiter='\\t', keep_default_na=False)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "text_train, y_train = df_train['document'].as_matrix(), df_train['label'].as_matrix()\n",
    "text_test = df_test['document'].as_matrix()\n",
    "y_test = df_test['label'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_tokenizer(text):\n",
    "    return twitter_tag.morphs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_tag = Twitter()\n",
    "\n",
    "cv = TfidfVectorizer(tokenizer=twitter_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "x_train = cv.fit_transform(text_train)\n",
    "x_test = cv.transform(text_test)\n",
    "result = lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성:\n",
      "['고달픔', '고담', '고대', '고대로', '고대소설', '고도', '고도리', '고독', '고독감', '고독고독', '고동', '고두림', '고두심', '고드헌터', '고든', '고등', '고등법원', '고등어', '고등학교', '고등학생']\n"
     ]
    }
   ],
   "source": [
    "feature_names = cv.get_feature_names()\n",
    "print(\"특성:\\n{}\".format(feature_names[8000:8020]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 점수 :  0.8861533333333333\n",
      "테스트 데이터 예측 값 :  [1 0 0 ... 1 0 1]\n",
      "테스트 데이터 점수 :  0.85176\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 데이터 점수 : \", result.score(x_train, y_train))\n",
    "print(\"테스트 데이터 예측 값 : \", result.predict(x_test))\n",
    "print(\"테스트 데이터 점수 : \", result.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM을 이용한 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "text_data, y_data = df_data['document'].as_matrix(), df_data['label'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Twitter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, metrics\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os.path\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "# 토큰 파서\n",
    "def twitter_tokenizer(text):\n",
    "    return twitter_tag.morphs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_tag = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = TfidfVectorizer(tokenizer=twitter_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data.pickle\t X_test_2.pickle  X_train_1.pickle\r\n",
      "X_test_1.pickle  X_test.pickle\t  X_train_2.pickle\r\n"
     ]
    }
   ],
   "source": [
    "!ls X*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tfidf 생성과 저장 - 단 파일이 없을 때만 !!\n",
    "if not os.path.isfile(\"X_data.pickle\"): \n",
    "    print('file does not exists')\n",
    "    X_data = cv.fit_transform(text_data)\n",
    "    pickle.dump(X_train, open(\"X_data.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 tfidf vector 데이터 읽기\n",
    "with open('X_data.pickle', 'rb') as f:\n",
    "    X_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 hjkim hjkim 24433014 Oct 28 18:39 X_data.pickle\r\n",
      "-rw-rw-r-- 1 hjkim hjkim  7782344 Oct 28 19:03 X_test_1.pickle\r\n",
      "-rw-rw-r-- 1 hjkim hjkim  5610600 Oct 28 18:56 X_test_2.pickle\r\n",
      "-rw-rw-r-- 1 hjkim hjkim  8170628 Oct 28 18:40 X_test.pickle\r\n",
      "-rw-rw-r-- 1 hjkim hjkim 23745856 Oct 28 19:02 X_train_1.pickle\r\n",
      "-rw-rw-r-- 1 hjkim hjkim 14084384 Oct 28 18:55 X_train_2.pickle\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al X*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "Y_data = np_utils.to_categorical(y_data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_data[:100000]\n",
    "X_test = X_data[100000:]\n",
    "\n",
    "Y_train = Y_data[:100000]\n",
    "Y_test = Y_data[100000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 61070 \n",
    "nb_classes = 2\n",
    "batch_size = 1024\n",
    "nb_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 104160)\n",
      "(50000, 104160)\n",
      "(100000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "Y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 1, 104160)\n",
      "(50000, 1, 104160)\n"
     ]
    }
   ],
   "source": [
    "# LSTM 학습을 위한 데이터 재배열 (Time step)\n",
    "X_train_rnn = X_train.A.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_rnn = X_test.A.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "print(X_train_rnn.shape)\n",
    "print(X_test_rnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def build_LSTM_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), return_sequences=True))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(Y_train.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100000/100000 [==============================] - 252s 3ms/step - loss: 0.5463 - acc: 0.7826\n",
      "Epoch 2/5\n",
      "100000/100000 [==============================] - 238s 2ms/step - loss: 0.2854 - acc: 0.8830\n",
      "Epoch 3/5\n",
      "100000/100000 [==============================] - 239s 2ms/step - loss: 0.2076 - acc: 0.9218\n",
      "Epoch 4/5\n",
      "100000/100000 [==============================] - 238s 2ms/step - loss: 0.1604 - acc: 0.9420\n",
      "Epoch 5/5\n",
      "100000/100000 [==============================] - 239s 2ms/step - loss: 0.1293 - acc: 0.9543\n"
     ]
    }
   ],
   "source": [
    "import keras.backend.tensorflow_backend as K\n",
    "with K.tf.device('/GPU:1'):\n",
    "    model_lstm = KerasClassifier(\n",
    "    build_fn=build_LSTM_model, \n",
    "    epochs=nb_epoch, \n",
    "    batch_size=batch_size)\n",
    "    \n",
    "    model_lstm.fit(X_train_rnn, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 셋 정답률 = 0.96941\n"
     ]
    }
   ],
   "source": [
    "y = model_lstm.predict(X_train_rnn)\n",
    "y_train = y_data[:100000]\n",
    "ac_score = metrics.accuracy_score(y_train, y)\n",
    "print(\"훈련 셋 정답률 =\", ac_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y :  [0 1 0 ... 0 1 1]\n",
      "Y_train[0] :  [[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "y_train[0] :  [0 1 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# predict 함수는 예측 결과를 0 or 1로 출력하므로\n",
    "# 학습과정에서 사용한 Y_train, Y_test 변수로 정확도 측정이 안됨\n",
    "# Y_train, Y_test는 [0, 1], [1, 0]의 형태로 해당하는 감정 컬럼(class)은 1, 다른 컬럼은 0으로 표시됨\n",
    "# 초기 y_data에 저장된 값을 그대로 활용하여 정확도를 측정\n",
    "\n",
    "print(\"y : \", y)\n",
    "print(\"Y_train[0] : \", Y_train)\n",
    "print(\"y_train[0] : \", y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 셋 정답률 = 0.83784\n"
     ]
    }
   ],
   "source": [
    "y = model_lstm.predict(X_test_rnn)\n",
    "y_test = y_data[100000:]\n",
    "ac_score = metrics.accuracy_score(y_test, y)\n",
    "print(\"테스트 셋 정답률 =\", ac_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
