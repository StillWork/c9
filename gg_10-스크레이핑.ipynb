{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹에서 원하는 정보를 추출하는 것\n",
    "- HTML과 XML 문서에서 정보를 추출할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Users/hwa-jongkim/anaconda3/lib/python3.6/site-packages (4.6.3)\n",
      "\u001b[33mYou are using pip version 18.0, however version 19.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1= 파이선으로 웹문서 읽기 \n",
      "p= 페이지 분석기능 \n",
      "p= 페이지 정렬 \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    " <h1> 파이선으로 웹문서 읽기 </h1>\n",
    " <p> 페이지 분석기능 </p>\n",
    " <p> 페이지 정렬 </p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "h1 = soup.html.body.h1\n",
    "p1 = soup.html.body.p\n",
    "p2 = p1.next_sibling.next_sibling\n",
    "\n",
    "print(\"h1=\"+ h1.string)\n",
    "print(\"p=\"+ p1.string)\n",
    "print(\"p=\"+ p2.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### id 를 사용하는 방법\n",
    "- 위와 같이 내부 구조를 일일이 파악하고 코딩하는 것은 복잡하다\n",
    "- find()를 사용하여 간단히 원하는 항목을 찾을 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title= 파이선으로 웹문서 읽기 \n",
      "body= 페이지 분석기능 \n"
     ]
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html><body>\n",
    " <h1 id=\"title\"> 파이선으로 웹문서 읽기 </h1>\n",
    " <p id=\"body\"> 페이지 분석기능 </p>\n",
    " <p> 페이지 정렬 </p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "title = soup.find(id=\"title\")\n",
    "body = soup.find(id=\"body\")\n",
    "\n",
    "print(\"title=\"+ title.string)\n",
    "print(\"body=\"+ body.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find_all()을 이용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver --> http://www.naver.com\n",
      "daum --> http://www.daum.com\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    " <ul>\n",
    "   <li><a href = \"http://www.naver.com\">naver</a></li>\n",
    "   <li><a href = \"http://www.daum.com\">daum</a></li>\n",
    " </ul>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "links = soup.find_all(\"a\")\n",
    "\n",
    "for aa in links:\n",
    "    href = aa.attrs[\"href\"]\n",
    "    text = aa.string\n",
    "    print(text, \"-->\", href)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOM 요소 파악하기\n",
    "- Document Object Model: XML이나 HTML 요소에 접근하는 구조를 나타낸다\n",
    "- DOM 요소의 속성이란 태그 뒤에 나오는 속성을 말한다 <a> 태그의 속성은 href이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>\\n <a href=\"a.html\">\\n  test\\n </a>\\n</p>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(\"<p><a href='a.html'> test </a></p>\", \"html.parser\")\n",
    "\n",
    "# 분석이 되었는지 확인\n",
    "soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <a> 태그 변수를 a에 할당하고 속성의 자료형 확인\n",
    "# a = soup.p.a\n",
    "a = soup.a\n",
    "type(a.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"a.html\"> test </a>\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'href': 'a.html'}\n"
     ]
    }
   ],
   "source": [
    "print(a.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# href 속성이 들어 있는지 확인\n",
    "'href' in a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'href' in a.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a.html'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 속성 값 확인\n",
    "a['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### urlopen() 사용 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기상청 육상 중기예보\n",
      "-------------\n",
      "기압골의 영향으로 22일은 제주도에 비가 오겠습니다.<br />그 밖의 날은 고기압의 영향으로 대체로 맑은 날이 많겠습니다.<br />기온은 평년(최저기온: -7~3℃, 최고기온: 5~11℃)보다 조금 높겠습니다.<br />강수량은 평년(1~4mm)보다 적겠으나, 제주도는 비슷하겠습니다.\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse as parse\n",
    "import urllib.request as req\n",
    "\n",
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "res = req.urlopen(url)\n",
    "soup = BeautifulSoup(res, 'html.parser')\n",
    "\n",
    "title = soup.find(\"title\").string\n",
    "wf = soup.find('wf').string\n",
    "print(title)\n",
    "print(\"-------------\")\n",
    "print(wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSS 선택자 사용하기\n",
    "- CSS 선택자를 사용해서 원하는 요소를 추출할 수 있다.\n",
    "- h1 과 li 태그를 추출하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1=  위키북스 도서 \n",
      "li=  게임 입문 \n",
      "li=  파이선 입문 \n",
      "li=  웹 디자인 입문 \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "<div id=\"meigen\">\n",
    " <h1> 위키북스 도서 </h1>\n",
    " <ul class=\"item\">\n",
    "   <li> 게임 입문 </li>\n",
    "   <li> 파이선 입문 </li>\n",
    "   <li> 웹 디자인 입문 </li>\n",
    " </ul>\n",
    "</div>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "# CSS 쿼리로 title 추출하기\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "h1 = soup.select_one(\"div#meigen > h1\").string\n",
    "print(\"h1=\", h1)\n",
    "\n",
    "li_list = soup.select(\"div#meigen > ul.item > li\")\n",
    "for li in li_list:\n",
    "    print(\"li=\", li.string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li> 게임 입문 </li>, <li> 파이선 입문 </li>, <li> 웹 디자인 입문 </li>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네이버 금융에서 환율정보 추출하기\n",
    "- 먼저 네이버 웹사이트에서 소스보기를 하여 어디에 환률정보가 있는지 파악해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as req\n",
    "url = \"http://info.finance.naver.com/marketindex\"\n",
    "res = req.urlopen(url)\n",
    "soup = BeautifulSoup(res, 'html.parser')\n",
    "price = soup.select_one(\"div.head_info > span.value\").string\n",
    "print(\"usd/krw=\", price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSS 자세히 알아보기\n",
    "- 웹 페이지의 검사 메뉴를 선택 (우측 버튼)\n",
    "- 특정 태그를 선택하고 다시 우측 버튼을 누르고 Copy - Copy selector를 선택하면 CSS 선택자가 클립보드에 저장된다 (아래 예시)\n",
    "\n",
    "#mw-content-text > div > ul:nth-child(6) > li > b > a\n",
    "\n",
    "- 위에서 nth-child(6)은 6번째에 있는 요소를 가리킨다\n",
    "- 이를 기반으로 작품목록을 가져오는 프로그램을 작성하겠다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "# 아래는 저자:윤동주 부분인데 이는 웹사이트에서 복사하면 된다.\n",
    "\n",
    "url = \"https://ko.wikisource.org/wiki/%EC%A0%80%EC%9E%90:%EC%9C%A4%EB%8F%99%EC%A3%BC\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "soup = BeautifulSoup(res, 'html.parser')\n",
    "a_list= soup.select(\"#mw-content-text > div > ul a\")\n",
    "for a in a_list:\n",
    "    name = a.string\n",
    "    print(\"-\", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSS를 활용하는 방법 외에 re (정규표현식)을 사용하여 필요한 데이터를 추출할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "html = \"\"\"\n",
    "<ul>\n",
    "   <li><a href=\"https://sample.com/foo\">fuga </li>\n",
    "   <li><a href=\"http://sample.com/okay\">okay </li>\n",
    "   <li><a href=\"https://sample.com/fuga\"> fuga* </li>\n",
    "   <li><a href=\"https://example.com/sample\"> aaa </li>\n",
    "</ul>\n",
    "\"\"\"\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li=soup.find_all(href=re.compile(r\"^https://\"))\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in li: print(e.attrs['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
